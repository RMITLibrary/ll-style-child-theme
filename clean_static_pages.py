import os
import re
import argparse
import shutil

# Set up argument parser
parser = argparse.ArgumentParser(description='Process HTML files in a static site.')
parser.add_argument('--input', type=str, default='lab.bitma.appx', help='Directory containing your static site files')
parser.add_argument('--output', type=str, default='learning-lab-static', help='Directory for output files')

# Parse the arguments
args = parser.parse_args()

# Define the directory containing your static site files
static_dir = args.input
output_dir = args.output

# Ensure output directory exists
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Regular expressions for the changes you want to make

# meta tags
# "aioseo_comment" - Remove comments generated by AIOSEO plugin - NOT BEING USED
# "aioseo_meta" - Remove meta tags generated by AIOSEO plugin
# "additional_meta_comment" - Remove comments indicating additional meta tags
# "og_site_name" - Replace the site name in Open Graph meta tags to include "RMIT Library"

# style stuff
# 5. "style_block" - Remove this block of styles - used for WordPress admin
# 6. "wp_block_css" - Remove CSS links for WordPress block library
# 7. "classic_theme_styles" - Remove inline styles for classic WordPress themes
# 8. "h5p_plugin_styles" - Remove CSS links for H5P plugin styles - plugin not in use

# favicon
# 9. "favicon_path" - Replace the old favicon with the global RMIT favicon

# page content
# 10. "lab_reference" - Replace reference to lab.bitma.app with learninglab.rmit.edu.au
# 11. "remove_url_before_mailto" - Remove any URL before "mailto:" in links, sitesucker does this
#12. "remove_index_html" - Remove index.html from the end of links

patterns = {
    # meta tags
    # "aioseo_comment": re.compile(r"<!--.*?All in One SEO.*?-->", re.DOTALL),
    "aioseo_meta": re.compile(r'<meta name="generator" content="All in One SEO \(AIOSEO\) 4\.7\.4\.2" />'),
    "additional_meta_comment": re.compile(r"<!-- START Additional meta tags not covered by wp_head -->"),
    "og_site_name": re.compile(r'<meta property="og:site_name" content="Learning Lab -" />'),

    # style stuff
    "style_block": re.compile(r"<style id='global-styles-inline-css'>.*?</style>", re.DOTALL),
    "wp_block_css": re.compile(r'<link[^>]*id=["\']wp-block-library-css["\'][^>]*>'),
    "classic_theme_styles": re.compile(r'<style[^>]*id=["\']classic-theme-styles-inline-css["\'][^>]*>.*?</style>', re.DOTALL),
    "h5p_plugin_styles": re.compile(r'<link[^>]*id=["\']h5p-plugin-styles-css["\'][^>]*>'),

    # favicon
    "favicon_path": re.compile(r"https://rmitlibrary.github.io/cdn/learninglab/illustration/dev-fav-icon.png"),

    # page content
    "lab_reference": re.compile(r"lab\.bitma\.app"),
    "remove_url_before_mailto": re.compile(r'"[^"]*mailto:'),
    "remove_index_html": re.compile(r"/index\.html")
}

# Function to perform all the replacements and removals

def clean_content(content):
    # meta tags
    #content = re.sub(patterns["aioseo_comment"], '', content)
    content = re.sub(patterns["aioseo_meta"], '', content)
    content = re.sub(patterns["additional_meta_comment"], '', content)
    content = re.sub(patterns["og_site_name"], '<meta property="og:site_name" content="Learning Lab - RMIT Library" />', content)

    # style stuff
    content = re.sub(patterns["style_block"], '', content)
    content = re.sub(patterns["wp_block_css"], '', content)
    content = re.sub(patterns["classic_theme_styles"], '', content)
    content = re.sub(patterns["h5p_plugin_styles"], '', content)

    # favicon
    content = re.sub(patterns["favicon_path"], 'https://www.rmit.edu.au/etc.clientlibs/rmit/clientlibs/clientlib-site/resources/favicon.png', content)

    # page content
    content = re.sub(patterns["lab_reference"], 'learninglab.rmit.edu.au', content)
    content = re.sub(patterns["remove_url_before_mailto"], '"mailto:', content)
    content = re.sub(patterns["remove_index_html"], '/', content)

    return content

# Function to clean the 404.html file specifically
def clean_404_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    # Remove any ../ from the content
    cleaned_content = content.replace('../', '/')
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(cleaned_content)
        
# Process each file in the static directory
for root, dirs, files in os.walk(static_dir):
    for file in files:
        file_path = os.path.join(root, file)
        relative_path = os.path.relpath(file_path, static_dir)
        output_file_path = os.path.join(output_dir, relative_path)

        # Create directories if they don't exist
        os.makedirs(os.path.dirname(output_file_path), exist_ok=True)

        if file.endswith(('.html', '.txt', '.xml', '.json')):
            # Read, clean, and write the content for HTML files
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                cleaned_content = clean_content(content)
            with open(output_file_path, 'w', encoding='utf-8') as output_file:
                output_file.write(cleaned_content)
        else:
            # Copy non-HTML files directly
            shutil.copy2(file_path, output_file_path)

# Move and rename the 404 redirect file
redirect_404_path = os.path.join(output_dir, 'redirect-404', 'index.html')
new_404_path = os.path.join(output_dir, '404.html')

if os.path.exists(redirect_404_path):
    # Move and rename the 404 file
    shutil.move(redirect_404_path, new_404_path)

    # Remove the redirect-404 directory from the output directory
    redirect_404_dir = os.path.join(output_dir, 'redirect-404')
    # print(f"Attempting to remove directory: {redirect_404_dir}")
    if os.path.exists(redirect_404_dir):
        try:
            shutil.rmtree(redirect_404_dir)
            # print("Directory removed successfully.")
        except Exception as e:
            print(f"Error removing directory: {e}")

# Clean the 404.html file to remove any ../
if os.path.exists(new_404_path):
    clean_404_file(new_404_path)
    print("Cleaned 404.html file to remove '../'")

# Remove /_downloads.html from the output directory
downloads_path = os.path.join(output_dir, '_downloads.html')
if os.path.exists(downloads_path):
    os.remove(downloads_path)
    print(f"Removed file: {downloads_path}")

# Rename page_sitemap.xml in the output directory
page_sitemap_path = os.path.join(output_dir, 'page-sitemap.xml')
new_sitemap_path = os.path.join(output_dir, 'sitemap.xml')  # Change to your desired new name
if os.path.exists(page_sitemap_path):
    shutil.move(page_sitemap_path, new_sitemap_path)
    print(f"Renamed sitemap: {page_sitemap_path} to {new_sitemap_path}")

def update_robots_txt(file_path):
    # Define the new content for the robots.txt file
    new_content = """User-agent: *
Disallow: /documentation/

Sitemap: https://learninglab.rmit.edu.au/sitemap.xml
"""

    # Write the new content to the file
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(new_content)

# Assuming the robots.ssl.txt file is in the output directory
robots_txt_path = os.path.join(output_dir, 'robots.ssl.txt')

# Update the robots.txt file
update_robots_txt(robots_txt_path)

# Rename default-sitemap.xsl
original_filename = 'default-sitemap.xsl.xml'
new_filename = 'default-sitemap.xsl'

# Rename page_sitemap.xml in the output directory
sitemap_xsl_path = os.path.join(output_dir, 'default-sitemap.xsl.xml')
new_sitemap_xsl_path = os.path.join(output_dir, 'default-sitemap.xsl')  # Change to your desired new name
if os.path.exists(sitemap_xsl_path):
    shutil.move(sitemap_xsl_path, new_sitemap_xsl_path)
    print(f"Renamed sitemap: {sitemap_xsl_path} to {new_sitemap_xsl_path}")

print("V2 - Content processing completed.")